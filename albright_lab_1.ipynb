{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbebeff6",
   "metadata": {},
   "source": [
    "#### Lab 1 : Streaming Data for Predictive Maintenance with Linear Regression - Based Alerts\n",
    "Albright Maduka  \n",
    "\n",
    "CSCN 8010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff1d82",
   "metadata": {},
   "source": [
    "##### Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46db5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a07d49",
   "metadata": {},
   "source": [
    "##### 1. Database Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0c2a4",
   "metadata": {},
   "source": [
    "###### 1.1 Connecting to the neon database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d5d6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to NeonDatabase successful!\n"
     ]
    }
   ],
   "source": [
    "# NeonDB connection string\n",
    "conn_str= 'postgresql://neondb_owner:npg_X0Fy7gmpTsWN@ep-withered-mud-adujci27-pooler.c-2.us-east-1.aws.neon.tech/Group1workshop?sslmode=require&channel_binding=require'\n",
    "\n",
    "# SQLAlchemy engine\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# Psycopg2 connection (using SSL)\n",
    "raw_conn = psycopg2.connect(\n",
    " dbname=\"Group1workshop\",\n",
    " user=\"neondb_owner\",\n",
    " password=\"npg_X0Fy7gmpTsWN\",\n",
    "host=\"ep-withered-mud-adujci27-pooler.c-2.us-east-1.aws.neon.tech\",\n",
    "port=\"5432\",\n",
    "sslmode=\"require\"\n",
    " )\n",
    "\n",
    "print(\"Connection to NeonDatabase successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d6ddc",
   "metadata": {},
   "source": [
    "###### 1.2 Checking the Table Structure (columns and datatypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8051939c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  column_name                 data_type\n",
      "0       trait                      text\n",
      "1       axis1          double precision\n",
      "2       axis2          double precision\n",
      "3       axis3          double precision\n",
      "4       axis4          double precision\n",
      "5       axis5          double precision\n",
      "6       axis6          double precision\n",
      "7       axis7          double precision\n",
      "8       axis8          double precision\n",
      "9        time  timestamp with time zone\n"
     ]
    }
   ],
   "source": [
    "# Text helps to safely define Sturctured Query Language (SQL) queries\n",
    "# Pandas helps to manipulate dataframes\n",
    "# engine is the connection to the database\n",
    "\n",
    "# Replace my table_name with staging_measurements\n",
    "table_name = \"staging_measurements\"\n",
    "\n",
    "# SQL query to list columns and datatypes\n",
    "q = text(f\"\"\" \n",
    "SELECT column_name, data_type\n",
    "FROM information_schema.columns\n",
    "WHERE table_name = '{table_name}'\n",
    "ORDER BY ordinal_position;\n",
    "\"\"\") \n",
    "\n",
    "# Run the query with SQLAlchemy engine\n",
    "df = pd.read_sql(q, engine)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f40a6",
   "metadata": {},
   "source": [
    "###### 1.3 Safe Time Conversion, Downloading and Preprocessing staging measurements from NeonDB and Saving as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27371c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows loaded: 79344\n",
      "     trait  axis1  axis2  axis3  axis4  axis5  axis6  axis7  axis8  \\\n",
      "0  current    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1  current    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2  current    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3  current    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4  current    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "                              time  \n",
      "0 2022-10-17 12:18:23.660000+00:00  \n",
      "1 2022-10-17 12:18:25.472000+00:00  \n",
      "2 2022-10-17 12:18:27.348000+00:00  \n",
      "3 2022-10-17 12:18:29.222000+00:00  \n",
      "4 2022-10-17 12:18:31.117000+00:00  \n",
      "Filtered columns: ['time', '__time_s', 'axis1', 'axis2', 'axis3', 'axis4', 'axis5', 'axis6', 'axis7', 'axis8']\n",
      "Data exported to ./data/original_training_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Table to read from\n",
    "TABLE = \"staging_measurements\"\n",
    "\n",
    "# Read the table into a DataFrame\n",
    "df = pd.read_sql(f'SELECT * FROM \"{TABLE}\";', engine)\n",
    "print(\"Rows loaded:\", len(df))\n",
    "print(df.head())\n",
    "\n",
    "# converting the time in my staging_measurements table to ISO 8601 format\n",
    "\n",
    "# checks if the table has a time column\n",
    "if \"time\" in df.columns:\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\", utc=True) # errors=coerce checks for invalid times and sets them to Nat (missing)\n",
    "    if df[\"time\"].notna().any():\n",
    "        # Create __time_s (elapsed seconds from the first timestamp)\n",
    "        t0 = df[\"time\"].min() # where t0 is the first timestamp\n",
    "        df[\"__time_s\"] = (df[\"time\"] - t0).dt.total_seconds() # __time_s time is coverted to seconds\n",
    "\n",
    "        # Store time back in ISO 8601 string format\n",
    "        df[\"time\"] = df[\"time\"].dt.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    else:\n",
    "        raise ValueError(\"`time` column could not be parsed to datetimes.\") #If pandas could not successfully convert any of the time values into valid dates/times,\n",
    "else:\n",
    "    raise KeyError(\"No `time` column found in the data.\")\n",
    "\n",
    "# Keep only the columns needed for Lab 1\n",
    "axis_cols = [c for c in df.columns if c.lower().startswith(\"axis\")]\n",
    "keep_cols = [\"time\", \"__time_s\"] + axis_cols\n",
    "df = df[keep_cols]\n",
    "\n",
    "print(\"Filtered columns:\", df.columns.tolist())\n",
    "\n",
    "# saving the original training data to CSV\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "out_path = \"./data/original_training_data.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Data exported to ./data/original_training_data.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eeb0c6",
   "metadata": {},
   "source": [
    "##### 2. Streaming simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e28fc",
   "metadata": {},
   "source": [
    "###### 2.1 Displaying the maximum and minimum current values in the axis of the original data and synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2f31bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original Data (TRAIN) - Max & Min\n",
      "axis1 -> Max: 23.6093, Min: 0.0\n",
      "axis2 -> Max: 51.71323, Min: 0.0\n",
      "axis3 -> Max: 41.85556, Min: 0.0\n",
      "axis4 -> Max: 15.6663, Min: 0.0\n",
      "axis5 -> Max: 20.75076, Min: 0.0\n",
      "axis6 -> Max: 20.93142, Min: 0.0\n",
      "axis7 -> Max: 8.10848, Min: 0.0\n",
      "axis8 -> Max: 5.90564, Min: 0.0\n",
      "\n",
      "Synthetic Data (TEST) - Max & Min\n",
      "axis1 -> Max: 8.855649127469295, Min: -8.923729773835545\n",
      "axis2 -> Max: 32.52315117280435, Min: -22.41087609326153\n",
      "axis3 -> Max: 26.0314144349465, Min: -17.733853606750458\n",
      "axis4 -> Max: 6.576776803235276, Min: -6.26844347861212\n",
      "axis5 -> Max: 8.67940667883882, Min: -8.315460084765235\n",
      "axis6 -> Max: 8.25967787182789, Min: -7.396414203649386\n",
      "axis7 -> Max: 9.27350726792753, Min: -8.341754711305176\n",
      "axis8 -> Max: 1.7599017520357634, Min: -1.592010091392268\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(\"./data/original_training_data.csv\") # Original training data\n",
    "test_df  = pd.read_csv(\"./data/synthetic_data.csv\") # Synthetic testing data\n",
    "\n",
    "# Choose axis columns (axis1..axis8)\n",
    "axis_cols = [c for c in train_df.columns if c.lower().startswith(\"axis\")]\n",
    "\n",
    "# Print max & min for each axis in TRAIN\n",
    "print(\" Original Data (TRAIN) - Max & Min\")\n",
    "for col in axis_cols:\n",
    "    print(f\"{col} -> Max: {train_df[col].max()}, Min: {train_df[col].min()}\") # Display max and min for each axis\n",
    "\n",
    "# Print max & min for each axis in TEST\n",
    "print(\"\\nSynthetic Data (TEST) - Max & Min\")\n",
    "for col in axis_cols:\n",
    "    print(f\"{col} -> Max: {test_df[col].max()}, Min: {test_df[col].min()}\") # Display max and min for each axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eebc3b0",
   "metadata": {},
   "source": [
    "###### 2.2 Calculating Range (Max - Min) for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e2b36a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Range in Original (Training) Data:\n",
      "axis1: 23.6093\n",
      "axis2: 51.71323\n",
      "axis3: 41.85556\n",
      "axis4: 15.6663\n",
      "axis5: 20.75076\n",
      "axis6: 20.93142\n",
      "axis7: 8.10848\n",
      "axis8: 5.90564\n",
      "\n",
      " Range in Synthetic (Testing) Data:\n",
      "axis1: 17.779378901304838\n",
      "axis2: 54.934027266065875\n",
      "axis3: 43.765268041696956\n",
      "axis4: 12.845220281847396\n",
      "axis5: 16.994866763604055\n",
      "axis6: 15.656092075477275\n",
      "axis7: 17.615261979232706\n",
      "axis8: 3.3519118434280313\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your datasets\n",
    "train_df = pd.read_csv(\"./data/original_training_data.csv\")\n",
    "test_df  = pd.read_csv(\"./data/synthetic_data.csv\")\n",
    "\n",
    "# Choose axis columns (axis1..axis8 typically)\n",
    "axis_cols = [c for c in train_df.columns if c.lower().startswith(\"axis\")]\n",
    "\n",
    "# Compute range for each axis in TRAIN\n",
    "train_ranges = {col: train_df[col].max() - train_df[col].min() for col in axis_cols} #finding the range of each axis\n",
    "\n",
    "# Compute range for each axis in TEST\n",
    "test_ranges = {col: test_df[col].max() - test_df[col].min() for col in axis_cols} #finding the range of each axis\n",
    "\n",
    "print(\" Range in Original (Training) Data:\")\n",
    "for col, r in train_ranges.items():\n",
    "    print(f\"{col}: {r}\")\n",
    "\n",
    "print(\"\\n Range in Synthetic (Testing) Data:\")\n",
    "for col, r in test_ranges.items():\n",
    "    print(f\"{col}: {r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b714f3cc",
   "metadata": {},
   "source": [
    "###### 2.3 Generating synthetic data that has same mean and standard deviation as the original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1445685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data saved: (79344, 10)\n",
      "\n",
      "Range comparison:\n",
      "axis1: Train=23.61, Test=18.51\n",
      "axis2: Train=51.71, Test=56.39\n",
      "axis3: Train=41.86, Test=44.08\n",
      "axis4: Train=15.67, Test=12.96\n",
      "axis5: Train=20.75, Test=19.18\n",
      "axis6: Train=20.93, Test=15.21\n",
      "axis7: Train=8.11, Test=19.22\n",
      "axis8: Train=5.91, Test=3.74\n"
     ]
    }
   ],
   "source": [
    "# Reloading the original training data \n",
    "df = pd.read_csv(\"./data/original_training_data.csv\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# It creates the Synthetic Dataset with the same mean and standard deviation as the original dataset.\n",
    "synthetic_df = pd.DataFrame()  # Makes a new empty DataFrame where your synthetic data will be stored.\n",
    "\n",
    "for col in df.columns:\n",
    "    if np.issubdtype(df[col].dtype, np.number):  # numeric columns\n",
    "        mu, sigma = df[col].mean(), df[col].std()  # mean (mu) and standard deviation (sigma)\n",
    "        synthetic_df[col] = np.random.normal(mu, sigma, len(df))  # random normal using mu & sigma\n",
    "    else:\n",
    "        # Keep non-numeric columns (like timestamps or IDs) unchanged\n",
    "        synthetic_df[col] = df[col]\n",
    "\n",
    "# Save synthetic data to a new CSV file in the data folder\n",
    "synthetic_df.to_csv(\"./data/synthetic_data.csv\", index=False)\n",
    "print(\"Synthetic data saved:\", synthetic_df.shape)\n",
    "\n",
    "# Validation: compare ranges\n",
    "train_ranges = {c: df[c].max() - df[c].min() for c in df.columns if \"axis\" in c}\n",
    "test_ranges  = {c: synthetic_df[c].max() - synthetic_df[c].min() for c in train_ranges}\n",
    "\n",
    "print(\"\\nRange comparison:\")\n",
    "for c in train_ranges:\n",
    "    print(f\"{c}: Train={train_ranges[c]:.2f}, Test={test_ranges[c]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab24b5",
   "metadata": {},
   "source": [
    "##### 3. Regression Models & Residual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5a162",
   "metadata": {},
   "source": [
    "###### 3.1 Creating a folder path for the Artifacts (output results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd464d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create artifacts\n",
    "DATA_DIR = Path(\"./data\")\n",
    "OUT_DIR  = Path(\"./artifacts\"); OUT_DIR.mkdir(parents=True, exist_ok=True) # used create the artifacts folder\n",
    "\n",
    "TRAIN_CSV = DATA_DIR / \"original_training_data.csv\" \n",
    "TEST_CSV  = DATA_DIR / \"synthetic_data.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7212344a",
   "metadata": {},
   "source": [
    "###### 3.2 Loading Train & Test and Converting Time to seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "275e5960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted timestamps to seconds (__time_s) in both train/test CSVs\n"
     ]
    }
   ],
   "source": [
    "# Reload datasets\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Makes sure that the dataframe has time column and it hasnt already been converted (no __times\n",
    "if \"time\" in train_df.columns and \"__time_s\" not in train_df.columns:\n",
    "    \n",
    "    # converting the training timestamps to real datetime values\n",
    "    train_df[\"time\"] = pd.to_datetime(train_df[\"time\"], errors=\"coerce\", utc=True)\n",
    "    # where t0 is the first timestamp\n",
    "    # __time_s is the elapsed time in seconds since the start time and __time_s = (time - t0). dt.total_seconds() converts all the time to seconds\n",
    "    t0 = train_df[\"time\"].min()\n",
    "    train_df[\"__time_s\"] = (train_df[\"time\"] - t0).dt.total_seconds()\n",
    "\n",
    "    # while this is for the test or synthetic data, we want to use the same reference start time (t0) as the training data\n",
    "    test_df[\"time\"] = pd.to_datetime(test_df[\"time\"], errors=\"coerce\", utc=True)\n",
    "    test_df[\"__time_s\"] = (test_df[\"time\"] - t0).dt.total_seconds()\n",
    "\n",
    "# Save back to CSVs\n",
    "train_df.to_csv(TRAIN_CSV, index=False)\n",
    "test_df.to_csv(TEST_CSV, index=False)\n",
    "\n",
    "# confirmation message that i has been converted\n",
    "print(\"Converted timestamps to seconds (__time_s) in both train/test CSVs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2ddb4",
   "metadata": {},
   "source": [
    "###### 3.3 Train Univariate Linear Regression (Time → Axis values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a2351ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved: artifacts\\model_params.csv\n"
     ]
    }
   ],
   "source": [
    "# Detect axis columns\n",
    "axis_cols = [c for c in train_df.columns if c.lower().startswith(\"axis\")]\n",
    "\n",
    "# Train one linear regression model per axis\n",
    "models = {}\n",
    "params_rows = []\n",
    "\n",
    "for col in axis_cols:\n",
    "    # where x =time in seconds and where y = axis values (current)\n",
    "    X = train_df[[\"__time_s\"]].values\n",
    "    y = pd.to_numeric(train_df[col], errors=\"coerce\").values\n",
    "    mask = ~np.isnan(X).ravel() & ~np.isnan(y) # where mask removes missing values so that the model trains cleanly\n",
    "\n",
    "    # function that fits a linear regression (y= slope * X(time) + intercept)\n",
    "    lr = LinearRegression().fit(X[mask].reshape(-1,1), y[mask]) # Train model\n",
    "    models[col] = lr\n",
    "\n",
    "    params_rows.append({\n",
    "        # extract the slope as lr.coef_[0] and intercept as lr.intercept_\n",
    "        \"axis\": col,\n",
    "        \"slope\": float(lr.coef_[0]),\n",
    "        \"intercept\": float(lr.intercept_)\n",
    "    })\n",
    "\n",
    "# Save model parameters to CSV\n",
    "params_df = pd.DataFrame(params_rows).sort_values(\"axis\")\n",
    "params_df.to_csv(OUT_DIR / \"model_params.csv\", index=False)\n",
    "print(\"Model parameters saved:\", OUT_DIR / \"model_params.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5862ec",
   "metadata": {},
   "source": [
    "###### 3.4 Residuals on Original Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d252510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resid = train_df[[\"__time_s\"]].copy()\n",
    "sigma_rows = []\n",
    "\n",
    "for col in axis_cols:\n",
    "    lr = models[col]\n",
    "    X = train_df[[\"__time_s\"]].values\n",
    "    y = pd.to_numeric(train_df[col], errors=\"coerce\").values\n",
    "    mask = ~np.isnan(X).ravel() & ~np.isnan(y)\n",
    "\n",
    "    y_hat = np.full(y.shape, np.nan, dtype=float)\n",
    "    y_hat[mask] = lr.predict(X[mask].reshape(-1,1))\n",
    "\n",
    "    resid = y - y_hat\n",
    "    train_resid[f\"{col}_resid\"] = resid\n",
    "\n",
    "    sigma_rows.append({\"axis\": col, \"sigma\": float(np.nanstd(resid, ddof=1))})\n",
    "\n",
    "# Create DataFrame of sigma values\n",
    "sigma_df = pd.DataFrame(sigma_rows)\n",
    "# Save training residuals\n",
    "train_resid.to_csv(OUT_DIR / \"train_residuals.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a44fab",
   "metadata": {},
   "source": [
    "##### 4. Testing Residuals with Thresholds (Anomaly Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e59561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds saved: artifacts\\thresholds.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "axis",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sigma",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MinC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MaxC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "T_seconds",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b42e8c83-3b24-430d-b6c1-c2755abc13f0",
       "rows": [
        [
         "0",
         "axis1",
         "2.162104481958948",
         "4.324208963917896",
         "6.486313445876844",
         "2"
        ],
        [
         "1",
         "axis2",
         "6.879731154508296",
         "13.759462309016593",
         "20.63919346352489",
         "2"
        ],
        [
         "2",
         "axis3",
         "5.111851167526421",
         "10.223702335052842",
         "15.335553502579263",
         "2"
        ],
        [
         "3",
         "axis4",
         "1.5748610151925515",
         "3.149722030385103",
         "4.7245830455776545",
         "2"
        ],
        [
         "4",
         "axis5",
         "2.1001717559875543",
         "4.200343511975109",
         "6.300515267962663",
         "2"
        ],
        [
         "5",
         "axis6",
         "1.815453305984058",
         "3.630906611968116",
         "5.446359917952174",
         "2"
        ],
        [
         "6",
         "axis7",
         "2.1667592029788394",
         "4.333518405957679",
         "6.500277608936518",
         "2"
        ],
        [
         "7",
         "axis8",
         "0.4230680564660255",
         "0.846136112932051",
         "1.2692041693980767",
         "2"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>axis</th>\n",
       "      <th>sigma</th>\n",
       "      <th>MinC</th>\n",
       "      <th>MaxC</th>\n",
       "      <th>T_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>axis1</td>\n",
       "      <td>2.162104</td>\n",
       "      <td>4.324209</td>\n",
       "      <td>6.486313</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>axis2</td>\n",
       "      <td>6.879731</td>\n",
       "      <td>13.759462</td>\n",
       "      <td>20.639193</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>axis3</td>\n",
       "      <td>5.111851</td>\n",
       "      <td>10.223702</td>\n",
       "      <td>15.335554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>axis4</td>\n",
       "      <td>1.574861</td>\n",
       "      <td>3.149722</td>\n",
       "      <td>4.724583</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>axis5</td>\n",
       "      <td>2.100172</td>\n",
       "      <td>4.200344</td>\n",
       "      <td>6.300515</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>axis6</td>\n",
       "      <td>1.815453</td>\n",
       "      <td>3.630907</td>\n",
       "      <td>5.446360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>axis7</td>\n",
       "      <td>2.166759</td>\n",
       "      <td>4.333518</td>\n",
       "      <td>6.500278</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>axis8</td>\n",
       "      <td>0.423068</td>\n",
       "      <td>0.846136</td>\n",
       "      <td>1.269204</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    axis     sigma       MinC       MaxC  T_seconds\n",
       "0  axis1  2.162104   4.324209   6.486313          2\n",
       "1  axis2  6.879731  13.759462  20.639193          2\n",
       "2  axis3  5.111851  10.223702  15.335554          2\n",
       "3  axis4  1.574861   3.149722   4.724583          2\n",
       "4  axis5  2.100172   4.200344   6.300515          2\n",
       "5  axis6  1.815453   3.630907   5.446360          2\n",
       "6  axis7  2.166759   4.333518   6.500278          2\n",
       "7  axis8  0.423068   0.846136   1.269204          2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T_SECONDS = 2  # event must persist ≥30s\n",
    "\n",
    "thresholds = sigma_df.copy()\n",
    "thresholds[\"MinC\"] = thresholds[\"sigma\"] * 2.0   # Alert\n",
    "thresholds[\"MaxC\"] = thresholds[\"sigma\"] * 3.0   # Error\n",
    "thresholds[\"T_seconds\"] = T_SECONDS\n",
    "\n",
    "# Saving Thresholds to CSV\n",
    "thresholds.to_csv(OUT_DIR / \"thresholds.csv\", index=False)\n",
    "print(\"Thresholds saved:\", OUT_DIR / \"thresholds.csv\")\n",
    "display(thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13faa4b8",
   "metadata": {},
   "source": [
    "##### 5. Alerts & Errors Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bdcf0",
   "metadata": {},
   "source": [
    "###### 5.1 Computing Residuals (errors) on Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "771ca457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test residuals saved: artifacts\\test_residuals.csv\n"
     ]
    }
   ],
   "source": [
    "# where test residuals dataframe = test_reside\n",
    "# where __time_s is the time in seconds\n",
    "test_resid = test_df[[\"__time_s\"]].copy()\n",
    "\n",
    "for col in axis_cols: # Loop through each axis column\n",
    "    lr = models[col] #using linear regression model\n",
    "    X = test_df[[\"__time_s\"]].values\n",
    "    y = pd.to_numeric(test_df[col], errors=\"coerce\").values\n",
    "    mask = ~np.isnan(X).ravel() & ~np.isnan(y) # Remove NaNs\n",
    "    # where mask is a boolean array (true or false)\n",
    "\n",
    "    y_hat = np.full(y.shape, np.nan, dtype=float) \n",
    "    y_hat[mask] = lr.predict(X[mask].reshape(-1,1)) # Predict only where we have valid data\n",
    "\n",
    "    # computing residuals\n",
    "    test_resid[f\"{col}_resid\"] = y - y_hat # residuals= observed or original - predicted\n",
    "\n",
    "#saving test residuals as csv\n",
    "test_resid.to_csv(OUT_DIR / \"test_residuals.csv\", index=False)\n",
    "print(\"Test residuals saved:\", OUT_DIR / \"test_residuals.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a6ac3",
   "metadata": {},
   "source": [
    "###### 5.2 Detect Alerts & Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fb49e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alerts log saved: artifacts\\alerts_log.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "axis",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "duration_sec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "peak_residual",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "17b2d1b0-6dd4-4677-9e1a-2582c293b2fb",
       "rows": [
        [
         "0",
         "axis1",
         "ALERT",
         "68286.89959510758",
         "73641.42902287265",
         "5354.529427765068",
         "4.649760859637626"
        ],
        [
         "1",
         "axis1",
         "ALERT",
         "13271.604790150246",
         "78780.40091433022",
         "65508.79612417998",
         "4.634452311517567"
        ],
        [
         "2",
         "axis1",
         "ALERT",
         "28441.14590400682",
         "69022.57389746764",
         "40581.42799346082",
         "4.795733267775035"
        ],
        [
         "3",
         "axis1",
         "ALERT",
         "49865.82249975131",
         "51275.68610476777",
         "1409.8636050164569",
         "4.524827342357581"
        ],
        [
         "4",
         "axis1",
         "ALERT",
         "56948.090909423016",
         "74296.40160434312",
         "17348.310694920103",
         "5.607649693945615"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>axis</th>\n",
       "      <th>level</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>peak_residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>axis1</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>68286.899595</td>\n",
       "      <td>73641.429023</td>\n",
       "      <td>5354.529428</td>\n",
       "      <td>4.649761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>axis1</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>13271.604790</td>\n",
       "      <td>78780.400914</td>\n",
       "      <td>65508.796124</td>\n",
       "      <td>4.634452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>axis1</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>28441.145904</td>\n",
       "      <td>69022.573897</td>\n",
       "      <td>40581.427993</td>\n",
       "      <td>4.795733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>axis1</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>49865.822500</td>\n",
       "      <td>51275.686105</td>\n",
       "      <td>1409.863605</td>\n",
       "      <td>4.524827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>axis1</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>56948.090909</td>\n",
       "      <td>74296.401604</td>\n",
       "      <td>17348.310695</td>\n",
       "      <td>5.607650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    axis  level    start_time      end_time  duration_sec  peak_residual\n",
       "0  axis1  ALERT  68286.899595  73641.429023   5354.529428       4.649761\n",
       "1  axis1  ALERT  13271.604790  78780.400914  65508.796124       4.634452\n",
       "2  axis1  ALERT  28441.145904  69022.573897  40581.427993       4.795733\n",
       "3  axis1  ALERT  49865.822500  51275.686105   1409.863605       4.524827\n",
       "4  axis1  ALERT  56948.090909  74296.401604  17348.310695       5.607650"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function finds continuous runs of True values in a condition\n",
    "# 1st function: find_runs\n",
    "def find_runs(time_series, mask_bool, min_sec):\n",
    "    # converts the true/false values into 1s and 0s\n",
    "    arr = mask_bool.to_numpy().astype(int)\n",
    "    \n",
    "    # where np.diff checks where the values change\n",
    "    # where it goes from 0 to 1 or 1 to o ie a run starts or end \n",
    "    change = np.diff(arr, prepend=0)\n",
    "    starts = np.where(change == 1)[0] # where the condition changes from False to True\n",
    "    ends   = np.where(change == -1)[0] - 1 # where the condition changes from True to False\n",
    "    if mask_bool.iloc[-1]:\n",
    "        ends = np.append(ends, len(mask_bool)-1)\n",
    "\n",
    "\n",
    "    events = [] # list to store events\n",
    "    for s, e in zip(starts, ends):\n",
    "        dur = float(time_series.iloc[e] - time_series.iloc[s])\n",
    "        # only keep it if the run lasted for at least min_sec seconds.\n",
    "        if dur >= min_sec:\n",
    "            events.append((s, e, dur)) # where s is the start index, e is the end index, dur is the duration in seconds\n",
    "    return events\n",
    "\n",
    "# 2nd function: log_axis_events\n",
    "# This function logs events for a given axis based on residual thresholds\n",
    "# This function checks for alerts and errors events and records them in details\n",
    "def log_axis_events(df, axis, MinC, MaxC, Tsec):\n",
    "    # Get the residuals for the axis and the time column\n",
    "    resid = df[f\"{axis}_resid\"]\n",
    "    time_series = df[\"__time_s\"]\n",
    "\n",
    "    # start an empty list to collects all the events for this axis\n",
    "    rows = []\n",
    "   \n",
    "    # checks for alerts and errors using the minimum and maximum thresholds conditions\n",
    "    for level, cond in [(\"ALERT\", resid >= MinC), (\"ERROR\", resid >= MaxC)]:\n",
    "        for s, e, dur in find_runs(time_series, cond, Tsec):\n",
    "            # Take residuals during the runs (from start to end).\n",
    "            seg = resid.iloc[s:e+1]\n",
    "\n",
    "            # Records one event row using axis, level, start_time, end_time, duration_sec, peak_residual\n",
    "            rows.append({\n",
    "                \"axis\": axis, # The axis being analyzed\n",
    "                \"level\": level, # ALERT or ERROR\n",
    "                \"start_time\": float(time_series.iloc[s]),\n",
    "                \"end_time\": float(time_series.iloc[e]),\n",
    "                \"duration_sec\": dur,\n",
    "                \"peak_residual\": float(seg.max())\n",
    "            })\n",
    "    return rows # Return list of event rows\n",
    "\n",
    "# Apply across all axes\n",
    "# Convert the thresholds DataFrame into a dictionary so you can quickly look up MinC, MaxC, T_seconds for each axis.\n",
    "thr = thresholds.set_index(\"axis\").to_dict(orient=\"index\")\n",
    "# loops through all axes: in these way grabs its thresholds, runs the log_axis_events function, and collects all the events into log_rows\n",
    "log_rows = []\n",
    "for axis in axis_cols:\n",
    "    a = thr[axis]\n",
    "    log_rows += log_axis_events(test_resid, axis, a[\"MinC\"], a[\"MaxC\"], a[\"T_seconds\"])\n",
    "\n",
    "# Save alerts log\n",
    "alerts_log = pd.DataFrame(log_rows)\n",
    "alerts_log.to_csv(OUT_DIR / \"alerts_log.csv\", index=False)\n",
    "print(\"Alerts log saved:\", OUT_DIR / \"alerts_log.csv\")\n",
    "display(alerts_log.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b27c9",
   "metadata": {},
   "source": [
    "##### 6. Visualization & Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29709504",
   "metadata": {},
   "source": [
    "###### 6.1 Comparing Observed vs Regression (Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d40b97ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST observed-vs-regression plots saved → artifacts\\plots\n"
     ]
    }
   ],
   "source": [
    "# Building a fast thresholds lookup for plotting\n",
    "thr = thresholds.set_index(\"axis\").to_dict(orient=\"index\")\n",
    "\n",
    "# saving the plots in the plots folder\n",
    "PLOTS_DIR = (OUT_DIR / \"plots\"); PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# defining the plotting funcion\n",
    "def plot_test_observed_vs_regression(test_df, test_resid_df, axis, lr, path): \n",
    "    # where test_df is the test or synthetic data, test_resid_df is the test residuals dataframe, axis is the axis column, lr is the linear regression model, path is the file path to save the plot\n",
    "    t = test_df[\"__time_s\"].values\n",
    "    y = pd.to_numeric(test_df[axis], errors=\"coerce\").values\n",
    "    m = ~np.isnan(t) & ~np.isnan(y)\n",
    "    t = t[m]; y = y[m]\n",
    "\n",
    "    # Predict using the regriession line\n",
    "    yhat = lr.predict(t.reshape(-1,1)) # give scikit learn  the required 2D shape\n",
    "\n",
    "    # get residuals\n",
    "    resid = test_resid_df[f\"{axis}_resid\"].loc[m].values\n",
    "    MinC  = thr[axis][\"MinC\"]\n",
    "    MaxC  = thr[axis][\"MaxC\"]\n",
    "\n",
    "   # plotting\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.scatter(t, y, s=6, alpha=0.6, label=\"Observed (TEST)\")\n",
    "    plt.plot(t, yhat, lw=1.5, label=\"Regression\")\n",
    "   \n",
    "    # Highlight points exceeding thresholds\n",
    "    over_min = resid >= MinC\n",
    "    over_max = resid >= MaxC\n",
    "    if over_min.any():\n",
    "        plt.scatter(t[over_min], y[over_min], s=14, marker=\"o\", label=\"≥ MinC (Alert)\")\n",
    "    if over_max.any():\n",
    "        plt.scatter(t[over_max], y[over_max], s=18, marker=\"x\", label=\"≥ MaxC (Error)\")\n",
    "\n",
    "    # labels\n",
    "    plt.title(f\"{axis}: Observed vs Regression (TEST)\")\n",
    "    plt.xlabel(\"elapsed seconds\"); plt.ylabel(axis); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(path, dpi=150); plt.close()\n",
    "\n",
    "# saving the plots in the plots folder\n",
    "for axis in axis_cols:\n",
    "    plot_test_observed_vs_regression(test_df, test_resid, axis, models[axis],\n",
    "                                     PLOTS_DIR / f\"{axis}_test_observed_vs_regression.png\")\n",
    "\n",
    "print(\"TEST observed-vs-regression plots saved →\", PLOTS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a621aa3",
   "metadata": {},
   "source": [
    "###### 6.2 Training Regression plot (visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a96569c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN regression plots saved → artifacts\\plots\n"
     ]
    }
   ],
   "source": [
    "# creates a folder called plots inside my artifacts folder\n",
    "PLOTS_DIR = (OUT_DIR / \"plots\"); PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# function to plot one axis at a time\n",
    "def plot_train_regression(df, axis, lr, path):\n",
    "    X = df[[\"__time_s\"]].values # where x is time in seconds.\n",
    "    y = pd.to_numeric(df[axis], errors=\"coerce\").values # where y is the axis observed values.\n",
    "    m = ~np.isnan(X).ravel() & ~np.isnan(y) #mask to filter out NaN values\n",
    "    X = X[m]; y = y[m]\n",
    "    yhat = lr.predict(X) #yhat is the predicted values from the linear regression model.\n",
    "\n",
    "    # creates the plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    # Scatter in blue\n",
    "    plt.scatter(X.ravel(), y, s=6, alpha=0.6, color=\"royalblue\", label=\"actual observed training data\")\n",
    "    # Regression line in orange\n",
    "    plt.plot(X.ravel(), yhat, linewidth=2, color=\"darkorange\", label=\"Regression line (the model's predicted trend)\")\n",
    "\n",
    "   #labels axes, adds title and legend \n",
    "    plt.xlabel(\"elapsed seconds\")\n",
    "    plt.ylabel(axis)\n",
    "    plt.title(f\"TRAIN: {axis} vs time (linear fit)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    " \n",
    " #Loops over all 8 axes, and saves 8 training regression plots.\n",
    "for axis in axis_cols:\n",
    "    plot_train_regression(train_df, axis, models[axis], PLOTS_DIR / f\"{axis}_train_regression.png\")\n",
    "\n",
    "print(\"TRAIN regression plots saved →\", PLOTS_DIR) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc0652",
   "metadata": {},
   "source": [
    "###### 6.3 Testing Residuals with Thresholds and events or testing the system for anomalie (Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "92c25d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST residual plots saved → artifacts\\plots\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of events (alerts/errors) by axis\n",
    "# collects events per axis\n",
    "events_by_axis = {a: [] for a in axis_cols}\n",
    "if len(alerts_log) > 0: # if there are any alerts or errors logged\n",
    "    for a in axis_cols:\n",
    "        events_by_axis[a] = alerts_log[alerts_log[\"axis\"] == a].to_dict(orient=\"records\")\n",
    "\n",
    "# function to plot residuals for one axis at a time\n",
    "def plot_test_residuals(df, axis, MinC, MaxC, events, path):\n",
    "    t = df[\"__time_s\"].values  # Where x is time in seconds\n",
    "    r = df[f\"{axis}_resid\"].values # where r is residuals = observed - predicted \n",
    "\n",
    "# plots the residuals  curve in steel blue. And draws alert threshold (green dashed line) and error threshold (red dash-dot line).\n",
    "    plt.figure(figsize=(10,5))\n",
    "    # Residual curve in steelblue\n",
    "    plt.plot(t, r, linewidth=1.2, color=\"steelblue\", label=\"residual line\")\n",
    "    # Threshold lines\n",
    "    plt.axhline(MinC, linestyle=\"--\", color=\"green\", label=\"MinC (Alert threshold)\")\n",
    "    plt.axhline(MaxC, linestyle=\"-.\", color=\"red\", label=\"MaxC (Error threshold)\")\n",
    "\n",
    "    # Event markers: red for ERROR, orange for ALERT\n",
    "    # loops through the list of logged events for that axis\n",
    "    for ev in events:\n",
    "\n",
    "        # Find the middle time of the event \n",
    "        mid_t = (float(ev[\"start_time\"]) + float(ev[\"end_time\"])) / 2\n",
    "\n",
    "        # Take the peak residual (largest deviation during the event)\n",
    "        mid_r = ev[\"peak_residual\"]\n",
    "\n",
    "        # Plot a marker at that point\n",
    "        if ev[\"level\"] == \"ERROR\":\n",
    "            plt.scatter([mid_t], [mid_r], s=40, marker=\"o\", color=\"red\", label=\"ERROR Event\")\n",
    "        else:\n",
    "            plt.scatter([mid_t], [mid_r],color=\"orange\", label=\"ALERT Event\")\n",
    "            # Where Mid_t is xaxis, Mid_r is yaxis, s=40 is the size of the marker\n",
    "\n",
    "    plt.xlabel(\"elapsed seconds\")\n",
    "    plt.ylabel(\"residual (observed - predicted)\")\n",
    "    plt.title(f\"TEST residuals: {axis}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "#Loops through all axes and saves residual plots with thresholds & events.\n",
    "for axis in axis_cols:\n",
    "    a = thr[axis]\n",
    "    plot_test_residuals(test_resid, axis, a[\"MinC\"], a[\"MaxC\"], events_by_axis[axis], PLOTS_DIR / f\"{axis}_test_residuals.png\")\n",
    "\n",
    "print(\"TEST residual plots saved →\", PLOTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffdc433",
   "metadata": {},
   "source": [
    "###### Note: Why is because there are no errors and only alerts is because the synthetic data did not produce residuals large enough and long enough to exceed the error threshold (MaxC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e807970",
   "metadata": {},
   "source": [
    "###### 6.4 Summary Dashoard of Alerts and Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "480cd09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary_dashboard.csv\n",
      "    axis  alert  error  longest_event_s\n",
      "0  axis1      8    NaN     46411.627930\n",
      "1  axis2      9    NaN     65509.208948\n",
      "2  axis3     14    NaN     81480.079580\n",
      "3  axis4      9    NaN     53146.592441\n",
      "4  axis5     11    NaN     98870.678102\n"
     ]
    }
   ],
   "source": [
    "# check if alerts_log is empty\n",
    "if alerts_log.empty:\n",
    "    summary = pd.DataFrame(columns=[\"axis\",\"alerts\",\"errors\",\"longest_event_s\"])\n",
    " # where alerts_log is empty, create an empty summary dataframe with the specified columns\n",
    "\n",
    "# otherwise, create a summary dataframe with counts of alerts and errors, and the longest event duration for each axis\n",
    "else:\n",
    "    counts = alerts_log.groupby([\"axis\",\"level\"]).size().unstack(fill_value=0)\n",
    "    longest = alerts_log.groupby(\"axis\")[\"duration_sec\"].max().rename(\"longest_event_s\")\n",
    "    summary = pd.concat([counts.reindex(columns=[\"ALERT\",\"ERROR\"]).rename(columns=str.lower), longest],\n",
    "                        axis=1).reset_index()\n",
    "\n",
    "summary.to_csv(OUT_DIR / \"summary_dashboard.csv\", index=False)\n",
    "print(\"Saved summary_dashboard.csv\"); print(summary.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
